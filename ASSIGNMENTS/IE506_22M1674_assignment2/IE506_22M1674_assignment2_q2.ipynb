{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Seed value\n",
    "seed=200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION A :\n",
    "\n",
    "Derivation of the given problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To derive the result, we take the derivative of the ridge regression objective function with respect to $\\beta$ and set it to zero:\n",
    "\n",
    "$\\nabla_{\\beta}({\\lambda}\\beta^T\\beta+(y-X\\beta)^T(y-X\\beta))=0$\n",
    "\n",
    "- After derivating it, we get the following form:\n",
    "\n",
    "$\\lambda\\beta + X^T(y-X\\beta) = 0$\n",
    "\n",
    "$\\lambda\\beta + X^Ty - X^TX\\beta = 0$\n",
    "\n",
    "$(X^TX + \\lambda I)\\beta = X^Ty$\n",
    "\n",
    "- Hence we can say that the given form in the question holds (HENCE PROVED)\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- Now we can get $\\beta$ in the form of :\n",
    "\n",
    "$ \\lambda\\beta = X^Ty-X^TX\\beta$\n",
    "\n",
    "$ \\lambda\\beta = X^T(y-X\\beta)$\n",
    "\n",
    "$ \\beta = \\frac{1}{\\lambda}[X^T(y-X\\beta)]$\n",
    "\n",
    "- Now, considering $\\alpha = \\frac{1}{\\lambda}(y - X\\beta)$. Then, $\\beta = \\frac{1}{\\lambda}X^T(y - X\\beta)$ can be written as $\\beta = X^T\\alpha$.  (HENCE PROVED)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "- Substituting $\\beta = X^T\\alpha$ into $(X^TX + \\lambda I)\\beta = X^Ty$, we get\n",
    "\n",
    "$(X^TX + \\lambda I)X^T\\alpha = X^Ty$\n",
    "\n",
    "$X(X^TX + \\lambda I)\\alpha = y$\n",
    "\n",
    "$\\alpha = (X^TX + \\lambda I)^{-1}y$\n",
    "\n",
    "Using the kernel function idea, we can replace $X^TX$ by the kernel matrix $K$. Therefore, $\\alpha = (K + \\lambda I)^{-1}y$.\n",
    "\n",
    "To represent the inference function $\\langle \\beta, x \\rangle$ using $\\alpha$ and kernels, we have\n",
    "\n",
    "$\\langle \\beta, x \\rangle = x^T\\beta = x^TX^T\\alpha = \\sum_{i=1}^{n}\\alpha_ik(x, x_i)$,\n",
    "\n",
    "where $k(x, x_i)$ is the kernel function representing the similarity between $x$ and $x_i$. Thus, we can use this kernel representation to make predictions in kernel ridge regression."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION B:\n",
    "\n",
    "- Read the data set in Data Q2.csv into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.578</td>\n",
       "      <td>93.00</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.185</td>\n",
       "      <td>5935.174070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.510</td>\n",
       "      <td>64.38</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.133</td>\n",
       "      <td>6044.657863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.730</td>\n",
       "      <td>64.21</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.152</td>\n",
       "      <td>6061.944778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.620</td>\n",
       "      <td>65.22</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.145</td>\n",
       "      <td>6108.043217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.450</td>\n",
       "      <td>67.69</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.189</td>\n",
       "      <td>6119.567827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>17.330</td>\n",
       "      <td>42.24</td>\n",
       "      <td>4.917</td>\n",
       "      <td>31.540</td>\n",
       "      <td>9443.855422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>7.010</td>\n",
       "      <td>76.40</td>\n",
       "      <td>4.920</td>\n",
       "      <td>65.890</td>\n",
       "      <td>9449.638554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>14.810</td>\n",
       "      <td>82.30</td>\n",
       "      <td>4.913</td>\n",
       "      <td>0.159</td>\n",
       "      <td>9449.638554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>12.090</td>\n",
       "      <td>77.40</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.104</td>\n",
       "      <td>9449.638554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>16.680</td>\n",
       "      <td>64.92</td>\n",
       "      <td>0.079</td>\n",
       "      <td>112.400</td>\n",
       "      <td>9449.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Temperature  Humidity  Wind Speed     Flow  Consumption\n",
       "0          5.578     93.00       0.082    0.185  5935.174070\n",
       "1         15.510     64.38       0.085    0.133  6044.657863\n",
       "2         15.730     64.21       0.084    0.152  6061.944778\n",
       "3         15.620     65.22       0.083    0.145  6108.043217\n",
       "4         15.450     67.69       0.083    0.189  6119.567827\n",
       "..           ...       ...         ...      ...          ...\n",
       "995       17.330     42.24       4.917   31.540  9443.855422\n",
       "996        7.010     76.40       4.920   65.890  9449.638554\n",
       "997       14.810     82.30       4.913    0.159  9449.638554\n",
       "998       12.090     77.40       0.073    0.104  9449.638554\n",
       "999       16.680     64.92       0.079  112.400  9449.990000\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Data_Q2.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Temperature    0\n",
       "Humidity       0\n",
       "Wind Speed     0\n",
       "Flow           0\n",
       "Consumption    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION C :\n",
    "\n",
    "- Perform standardization of each column in the data frame and create a new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.131628e-16</td>\n",
       "      <td>1.492140e-16</td>\n",
       "      <td>6.927792e-17</td>\n",
       "      <td>1.421085e-17</td>\n",
       "      <td>-1.477929e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.170116e+00</td>\n",
       "      <td>-2.907045e+00</td>\n",
       "      <td>-6.501680e-01</td>\n",
       "      <td>-6.677073e-01</td>\n",
       "      <td>-3.448482e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.397174e-01</td>\n",
       "      <td>-7.556299e-01</td>\n",
       "      <td>-6.423859e-01</td>\n",
       "      <td>-6.651830e-01</td>\n",
       "      <td>-6.787327e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.896711e-01</td>\n",
       "      <td>2.419695e-01</td>\n",
       "      <td>-6.405548e-01</td>\n",
       "      <td>-5.240777e-01</td>\n",
       "      <td>1.095636e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.782641e-01</td>\n",
       "      <td>8.867375e-01</td>\n",
       "      <td>1.570037e+00</td>\n",
       "      <td>3.081102e-01</td>\n",
       "      <td>7.164880e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.467526e+00</td>\n",
       "      <td>1.539466e+00</td>\n",
       "      <td>1.608948e+00</td>\n",
       "      <td>6.404628e+00</td>\n",
       "      <td>1.934698e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Temperature      Humidity    Wind Speed          Flow   Consumption\n",
       "count  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03  1.000000e+03\n",
       "mean   2.131628e-16  1.492140e-16  6.927792e-17  1.421085e-17 -1.477929e-15\n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00\n",
       "min   -2.170116e+00 -2.907045e+00 -6.501680e-01 -6.677073e-01 -3.448482e+00\n",
       "25%   -7.397174e-01 -7.556299e-01 -6.423859e-01 -6.651830e-01 -6.787327e-01\n",
       "50%    1.896711e-01  2.419695e-01 -6.405548e-01 -5.240777e-01  1.095636e-01\n",
       "75%    7.782641e-01  8.867375e-01  1.570037e+00  3.081102e-01  7.164880e-01\n",
       "max    2.467526e+00  1.539466e+00  1.608948e+00  6.404628e+00  1.934698e+00"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new=(df-df.mean())/df.std()\n",
    "df_new.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION D:\n",
    "\n",
    "-  Split the data into two sets such that 80% of the data is considered as set T1 and 20% of the data is considered as set T2. Justify if the splits T1 and T2 have similar spread in Consumption column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of T1 (X_train, y_train): (800, 5)\n",
      "Shape of T2 (X_test, y_test): (200, 5)\n",
      "\n",
      "Mean Consumption in T1: 0.002711724815472447\n",
      "\n",
      "Variance of Consumption in T1: 1.0078065744582132\n",
      "\n",
      "Mean Consumption in T2: -0.01084689926189765\n",
      "\n",
      "Variance of Consumption in T2: 0.9636266331376501\n"
     ]
    }
   ],
   "source": [
    "# Split data into T1 and T2\n",
    "T1,T2 = train_test_split(df_new, test_size=0.2,random_state=seed)\n",
    "\n",
    "# Check the shape of T1 and T2\n",
    "print(\"Shape of T1 (X_train, y_train):\",T1.shape)\n",
    "print(\"Shape of T2 (X_test, y_test):\", T2.shape)\n",
    "\n",
    "\n",
    "# Calculate mean and standard deviation of Consumption for T1 and T2\n",
    "consumption_mean_T1 = np.mean(T1['Consumption'])\n",
    "consumption_std_T1 = np.std(T1['Consumption'])\n",
    "consumption_mean_T2 = np.mean(T2['Consumption'])\n",
    "consumption_std_T2 = np.std(T2['Consumption'])\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nMean Consumption in T1:\", consumption_mean_T1)\n",
    "print(\"\\nVariance of Consumption in T1:\", consumption_std_T1**2)\n",
    "print(\"\\nMean Consumption in T2:\", consumption_mean_T2)\n",
    "print(\"\\nVariance of Consumption in T2:\", consumption_std_T2**2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMENTS :\n",
    "\n",
    "- To check the spread of the Consumption column we have to check the mean and variance of the split datasets. So I have computed the mean and variance of datasets T1 and T2. As we can see that, the mean and variances are nearly similar to each other so we can say that the Consumption column has similar spread is justified."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION E :\n",
    "\n",
    "- Using T1 as training data, train kernel ridge regression model. Use RBF kernel and tune the gamma parameter using 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 1.0, 'gamma': 10}\n",
      "Root Mean squared error: 0.8890653757120288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split T1 into features (X) and target (y)\n",
    "X_train = T1.drop('Consumption', axis=1)\n",
    "y_train = T1['Consumption']\n",
    "\n",
    "# Split T2 into features (X) and target (y)\n",
    "X_test = T2.drop('Consumption', axis=1)\n",
    "y_test = T2['Consumption']\n",
    "\n",
    "# Define the kernel ridge regression model with RBF kernel\n",
    "model = KernelRidge(kernel='rbf')\n",
    "\n",
    "# Define the range of hyperparameters to tune\n",
    "param_grid = {'alpha':np.array([0.001,0.01,0.1,1,10,100]) ,'gamma': [0.01, 0.1, 1,5,10,15,20,50,100]}\n",
    "\n",
    "# Define the grid search object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding mean squared error\n",
    "print('Best hyperparameters:', grid_search.best_params_)\n",
    "print('Root Mean squared error:',-grid_search.best_score_ )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION F :\n",
    "\n",
    "- Compute and display the RMSE and R2 values on the training set T1 and test set T2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Train Set: 0.66\n",
      "RMSE on Test Set: 0.83\n",
      "\n",
      "R2 on Train Set: 0.57\n",
      "R2 on Test Set: 0.29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# make predictions on T1 and T2\n",
    "y_train_pred = grid_search.predict(X_train)\n",
    "y_test_pred = grid_search.predict(X_test)\n",
    "\n",
    "# calculate RMSE on T1 and T2\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# calculate R2 on T1 and T2\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"RMSE on Train Set: {:.2f}\".format(rmse_train))\n",
    "print(\"RMSE on Test Set: {:.2f}\".format(rmse_test))\n",
    "print(\"\\nR2 on Train Set: {:.2f}\".format(r2_train))\n",
    "print(\"R2 on Test Set: {:.2f}\".format(r2_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION G:\n",
    "\n",
    "- Consider the original data in Data Q2.csv and load it into a different pandas dataframe called frame2. Add another column with name Class to the data frame frame2 such that the following hold:\n",
    "1. samples having Consumption values ≤ 6500 are labeled as class 1\n",
    "2. samples having Consumption values > 6500 and ≤ 7000 are labeled as class 2\n",
    "3. samples having Consumption values > 7000 and ≤ 7500 are labeled as class 3\n",
    "4. samples having Consumption values > 7500 and ≤ 8000 are labeled as class 4\n",
    "5. samples having Consumption values > 8000 and ≤ 8500 are labeled as class 5\n",
    "6. samples having Consumption values > 8500 and ≤ 9000 are labeled as class 6\n",
    "7.  samples having Consumption values > 9000 are labeled as class 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in unique classes : (array([1, 2, 3, 4, 5, 6, 7]), array([ 15,  27, 103, 218, 280, 255, 102], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Load data into dataframe\n",
    "frame2 = pd.read_csv(\"Data_Q2.csv\")\n",
    "\n",
    "# Add Class column\n",
    "conditions = [\n",
    "    frame2['Consumption'] <= 6500,\n",
    "    (frame2['Consumption'] > 6500) & (frame2['Consumption'] <= 7000),\n",
    "    (frame2['Consumption'] > 7000) & (frame2['Consumption'] <= 7500),\n",
    "    (frame2['Consumption'] > 7500) & (frame2['Consumption'] <= 8000),\n",
    "    (frame2['Consumption'] > 8000) & (frame2['Consumption'] <= 8500),\n",
    "    (frame2['Consumption'] > 8500) & (frame2['Consumption'] <= 9000),\n",
    "    frame2['Consumption'] > 9000\n",
    "]\n",
    "choices = [1, 2, 3, 4, 5, 6,7]\n",
    "\n",
    "frame2['Class'] = pd.Series(np.select(conditions, choices))\n",
    "\n",
    "frame2\n",
    "\n",
    "print(\"Number of datapoints in unique classes :\", np.unique(frame2['Class'],return_counts=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since there is a class imbalance we will have to resample the classes before training for proper classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION H:\n",
    "\n",
    "- Perform standardization of samples in frame2 belonging to each class separately. Ignore Class column during standardization procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000001EED1B868B0>\n"
     ]
    }
   ],
   "source": [
    "# Group samples by class label\n",
    "groups = frame2.groupby('Class')\n",
    "print(groups)\n",
    "# Standardize each group separately\n",
    "for name, group in groups:\n",
    "    # Get the indices of columns to standardize (exclude 'Class')\n",
    "    col_indices = [i for i, col in enumerate(group.columns) if col != 'Class']\n",
    "    # Standardize the columns using mean and std of the group\n",
    "    group.iloc[:, col_indices] = (group.iloc[:, col_indices] - group.iloc[:, col_indices].mean()) / group.iloc[:, col_indices].std()\n",
    "\n",
    "    # Replace the group in the original dataframe with standardized values\n",
    "    frame2.loc[group.index] = group\n",
    "#frame2[frame2['Class']==5].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Consumption</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.633251</td>\n",
       "      <td>1.510316</td>\n",
       "      <td>-0.491477</td>\n",
       "      <td>-0.353228</td>\n",
       "      <td>-1.860482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.046563</td>\n",
       "      <td>-1.473479</td>\n",
       "      <td>0.561688</td>\n",
       "      <td>-0.398291</td>\n",
       "      <td>-1.259987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.105922</td>\n",
       "      <td>-1.491202</td>\n",
       "      <td>0.210633</td>\n",
       "      <td>-0.381826</td>\n",
       "      <td>-1.165172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.076242</td>\n",
       "      <td>-1.385904</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.387892</td>\n",
       "      <td>-0.912332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.030374</td>\n",
       "      <td>-1.128393</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.349762</td>\n",
       "      <td>-0.849122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Wind Speed      Flow  Consumption  Class\n",
       "0    -1.633251  1.510316   -0.491477 -0.353228    -1.860482      1\n",
       "1     1.046563 -1.473479    0.561688 -0.398291    -1.259987      1\n",
       "2     1.105922 -1.491202    0.210633 -0.381826    -1.165172      1\n",
       "3     1.076242 -1.385904   -0.140422 -0.387892    -0.912332      1\n",
       "4     1.030374 -1.128393   -0.140422 -0.349762    -0.849122      1"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION I:\n",
    "\n",
    "- Split frame2 into train and test splits T3 and T4, such that the samples in T3 are the same as in T1. Consider T3 as training set, ignore the Consumption column and considering Class as labels, train a kernel SVM model with RBF kernel. Tune gamma parameter using 5\n",
    "fold cross-validation. Take care of class imbalance issues if they exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in unique classes : (array([1, 2, 3, 4, 5, 6, 7]), array([279, 275, 269, 238, 236, 246, 263], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Taking care of class imbalance\n",
    "from imblearn.combine import SMOTETomek,SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X=frame2.drop(columns=['Class'])\n",
    "y=frame2['Class']\n",
    "\n",
    "# Applying hybrid resampling. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=seed,sampling_strategy='all') \n",
    "#smt=SMOTE(random_state=seed)\n",
    "\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X, y)  # Resmapling done to generate nearabout equal classes\n",
    "\n",
    "frame2_new=pd.DataFrame(X_res)\n",
    "frame2_new['Class']=y_res\n",
    "print(\"Number of datapoints in unique classes :\", np.unique(frame2_new['Class'],return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Consumption</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.633251</td>\n",
       "      <td>1.510316</td>\n",
       "      <td>-0.491477</td>\n",
       "      <td>-0.353228</td>\n",
       "      <td>-1.860482</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.046563</td>\n",
       "      <td>-1.473479</td>\n",
       "      <td>0.561688</td>\n",
       "      <td>-0.398291</td>\n",
       "      <td>-1.259987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.105922</td>\n",
       "      <td>-1.491202</td>\n",
       "      <td>0.210633</td>\n",
       "      <td>-0.381826</td>\n",
       "      <td>-1.165172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.076242</td>\n",
       "      <td>-1.385904</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.387892</td>\n",
       "      <td>-0.912332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.030374</td>\n",
       "      <td>-1.128393</td>\n",
       "      <td>-0.140422</td>\n",
       "      <td>-0.349762</td>\n",
       "      <td>-0.849122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  Humidity  Wind Speed      Flow  Consumption  Class\n",
       "0    -1.633251  1.510316   -0.491477 -0.353228    -1.860482      1\n",
       "1     1.046563 -1.473479    0.561688 -0.398291    -1.259987      1\n",
       "2     1.105922 -1.491202    0.210633 -0.381826    -1.165172      1\n",
       "3     1.076242 -1.385904   -0.140422 -0.387892    -0.912332      1\n",
       "4     1.030374 -1.128393   -0.140422 -0.349762    -0.849122      1"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame2_new.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After applying resampling technique we can see that although we cannot achieve exactly equal number of classes, I have achieved a near similar class distribution.\n",
    "\n",
    "- The reason we cannot achieve the equal number of classes is because the number of samples in the majority class may not be divisible by the number of classes and also by the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1444, 5) (362, 5)\n",
      "Number of datapoints in unique classes : (array([1, 2, 3, 4, 5, 6, 7]), array([223, 220, 215, 190, 189, 197, 210], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# Split data into T3 and T4\n",
    "'''\n",
    "Since in the question it is explicitly mentioned that we must keep the samples in T1 and T3 same. However it is also written that any class \n",
    "imbalance is to be taken care of. So I will be using startify function in this case.\n",
    "'''\n",
    "T3,T4 = train_test_split(frame2_new, test_size=0.2,stratify=frame2_new['Class'],random_state=seed)  # The seed value replicates the samples in T1 in T3\n",
    "T3.drop(columns=['Consumption'],inplace=True)\n",
    "T4.drop(columns=['Consumption'],inplace=True)\n",
    "print(T3.shape,T4.shape)\n",
    "print(\"Number of datapoints in unique classes :\", np.unique(T3['Class'],return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.289994</td>\n",
       "      <td>1.051699</td>\n",
       "      <td>1.686249</td>\n",
       "      <td>-0.217260</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>-1.104974</td>\n",
       "      <td>-0.053003</td>\n",
       "      <td>1.333921</td>\n",
       "      <td>-0.234959</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.858229</td>\n",
       "      <td>-0.487858</td>\n",
       "      <td>-0.349970</td>\n",
       "      <td>-0.353097</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.696646</td>\n",
       "      <td>-2.409560</td>\n",
       "      <td>-0.751485</td>\n",
       "      <td>-0.729339</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>-0.423593</td>\n",
       "      <td>0.807291</td>\n",
       "      <td>-0.541347</td>\n",
       "      <td>-0.311039</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature  Humidity  Wind Speed      Flow  Class\n",
       "580      0.289994  1.051699    1.686249 -0.217260      6\n",
       "421     -1.104974 -0.053003    1.333921 -0.234959      5\n",
       "1267     0.858229 -0.487858   -0.349970 -0.353097      2\n",
       "506      0.696646 -2.409560   -0.751485 -0.729339      5\n",
       "1466    -0.423593  0.807291   -0.541347 -0.311039      3"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T3.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we can observe that we get near similar class distribution with slight deviation which will not affect much. This is within the capabilties of the model.\n",
    "\n",
    "- Also perfect class balance of 1:1 is not possible due to odd number of samples in majority class and the problem mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 100.0, 'gamma': 1.0}\n",
      "Training accuracy: 0.9889196675900277\n",
      "Test accuracy: 0.9088397790055248\n"
     ]
    }
   ],
   "source": [
    "# train a kernel SVM model with RBF kernel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# define the parameter grid for hyperparameter tuning\n",
    "param_grid = {'C':np.array([0.001,0.01,0.1,1,10,50,100]) ,'gamma': np.array([0.001,0.01,0.1,1,10,100,1000])}\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "# define the kernel SVM model\n",
    "svm = SVC(kernel='rbf', class_weight='balanced')  # We have used class weight balanced to take care of class balance issues in training\n",
    "\n",
    "# perform hyperparameter tuning using 5-fold cross-validation\n",
    "best_classification_model = GridSearchCV(svm, param_grid,cv=cv,scoring='accuracy')\n",
    "best_classification_model .fit(T3.iloc[:, :-1], T3['Class'])\n",
    "\n",
    "# get the best hyperparameters and the corresponding model\n",
    "best_params = best_classification_model .best_params_\n",
    "best_svm = best_classification_model .best_estimator_\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Training accuracy:\", best_svm.score(T3.iloc[:, :-1], T3['Class']))\n",
    "print(\"Test accuracy:\", best_svm.score(T4.iloc[:, :-1], T4['Class']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION J:\n",
    "\n",
    "- Now consider samples belonging to a particular class i in T3: build a kernel ridge regression model with RBF kernel (ignore the Class column for this task). Tune gamma parameter using 5 fold cross-validation restricted to samples belonging to only class i. Repeat this\n",
    "for each class. Thus, at the end, for each class i, you would now have a kernel ridge regression model Mi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1444, 6) (362, 6)\n",
      "Number of datapoints in unique classes : (array([1, 2, 3, 4, 5, 6, 7]), array([223, 220, 215, 190, 189, 197, 210], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "T3,T4 = train_test_split(frame2_new, test_size=0.2,stratify=frame2_new['Class'],random_state=seed)  # The seed value replicates the samples in T1 in T3\n",
    "#T3.drop(columns=['Consumption'],inplace=True)\n",
    "#T4.drop(columns=['Consumption'],inplace=True)\n",
    "print(T3.shape,T4.shape)\n",
    "print(\"Number of datapoints in unique classes :\", np.unique(T3['Class'],return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Flow</th>\n",
       "      <th>Consumption</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.289994</td>\n",
       "      <td>1.051699</td>\n",
       "      <td>1.686249</td>\n",
       "      <td>-0.217260</td>\n",
       "      <td>-1.052016</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>-1.104974</td>\n",
       "      <td>-0.053003</td>\n",
       "      <td>1.333921</td>\n",
       "      <td>-0.234959</td>\n",
       "      <td>-0.231781</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.858229</td>\n",
       "      <td>-0.487858</td>\n",
       "      <td>-0.349970</td>\n",
       "      <td>-0.353097</td>\n",
       "      <td>-1.001939</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.696646</td>\n",
       "      <td>-2.409560</td>\n",
       "      <td>-0.751485</td>\n",
       "      <td>-0.729339</td>\n",
       "      <td>1.074272</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>-0.423593</td>\n",
       "      <td>0.807291</td>\n",
       "      <td>-0.541347</td>\n",
       "      <td>-0.311039</td>\n",
       "      <td>1.290980</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>-1.756365</td>\n",
       "      <td>0.707177</td>\n",
       "      <td>-0.748033</td>\n",
       "      <td>1.176771</td>\n",
       "      <td>-0.158708</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>1.042218</td>\n",
       "      <td>-1.185274</td>\n",
       "      <td>-0.085383</td>\n",
       "      <td>-0.354789</td>\n",
       "      <td>-0.898672</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.359424</td>\n",
       "      <td>0.843192</td>\n",
       "      <td>1.500722</td>\n",
       "      <td>-0.725206</td>\n",
       "      <td>-0.719937</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.755809</td>\n",
       "      <td>0.790952</td>\n",
       "      <td>-0.842531</td>\n",
       "      <td>3.256180</td>\n",
       "      <td>1.047180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>-0.396025</td>\n",
       "      <td>-0.186230</td>\n",
       "      <td>-0.749327</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>-0.158708</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Temperature  Humidity  Wind Speed      Flow  Consumption  Class\n",
       "580      0.289994  1.051699    1.686249 -0.217260    -1.052016      6\n",
       "421     -1.104974 -0.053003    1.333921 -0.234959    -0.231781      5\n",
       "1267     0.858229 -0.487858   -0.349970 -0.353097    -1.001939      2\n",
       "506      0.696646 -2.409560   -0.751485 -0.729339     1.074272      5\n",
       "1466    -0.423593  0.807291   -0.541347 -0.311039     1.290980      3\n",
       "...           ...       ...         ...       ...          ...    ...\n",
       "424     -1.756365  0.707177   -0.748033  1.176771    -0.158708      5\n",
       "1102     1.042218 -1.185274   -0.085383 -0.354789    -0.898672      1\n",
       "188      0.359424  0.843192    1.500722 -0.725206    -0.719937      4\n",
       "11      -0.755809  0.790952   -0.842531  3.256180     1.047180      1\n",
       "425     -0.396025 -0.186230   -0.749327 -0.024521    -0.158708      5\n",
       "\n",
       "[1444 rows x 6 columns]"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'alpha': 0.01, 'gamma': 2} 0.11348093114024409\n",
      "2 {'alpha': 0.1, 'gamma': 2} 0.41678802993354785\n",
      "3 {'alpha': 0.25, 'gamma': 3} 0.714454325989627\n",
      "4 {'alpha': 0.5, 'gamma': 10} 0.8410808729285927\n",
      "5 {'alpha': 0.5, 'gamma': 15} 0.9314543121498076\n",
      "6 {'alpha': 0.5, 'gamma': 2} 0.939312423038235\n",
      "7 {'alpha': 0.1, 'gamma': 10} 0.6547994274855914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# create a dictionary to store the models for each class\n",
    "all_models = {}\n",
    "\n",
    "# loop over the classes\n",
    "for i in choices:\n",
    "    # filter out samples belonging to class i from T3\n",
    "    Ti = T3[T3['Class'] == i].drop(columns=['Class'],axis=1)    \n",
    "    # split Ti into X and y\n",
    "    X = Ti.drop(columns=['Consumption']).to_numpy()\n",
    "    y = Ti['Consumption'].to_numpy()\n",
    "    \n",
    "    # tune gamma using 5-fold cross-validation\n",
    "    # Define the range of hyperparameters to tune\n",
    "    param_grid = {'alpha':np.array([0.001,0.01,0.1,0.5,0.25,1,10]) ,'gamma': [0.01, 0.1, 0.5,0.25,1, 2, 3, 5,10,15,18,20]}\n",
    "\n",
    "    # Define the kernel ridge regression model with RBF kernel\n",
    "    model = KernelRidge(kernel='rbf')\n",
    "    # Define the grid search object with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_root_mean_squared_error')#neg_mean_squared_error\n",
    "\n",
    "    # Fit the grid search object to the training data\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_model=KernelRidge(kernel='rbf',alpha=grid_search.best_params_['alpha'],gamma=grid_search.best_params_['gamma'])\n",
    "\n",
    "    best_model.fit(X, y)\n",
    "    \n",
    "    print(i,grid_search.best_params_,-grid_search.best_score_ )\n",
    "\n",
    "    # store the model for class i\n",
    "    all_models[i] = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: KernelRidge(alpha=0.01, gamma=2, kernel='rbf'), 2: KernelRidge(alpha=0.1, gamma=2, kernel='rbf'), 3: KernelRidge(alpha=0.25, gamma=3, kernel='rbf'), 4: KernelRidge(alpha=0.5, gamma=10, kernel='rbf'), 5: KernelRidge(alpha=0.5, gamma=15, kernel='rbf'), 6: KernelRidge(alpha=0.5, gamma=2, kernel='rbf'), 7: KernelRidge(alpha=0.1, gamma=10, kernel='rbf')}\n"
     ]
    }
   ],
   "source": [
    "print(all_models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMENTS :\n",
    "\n",
    "- Here I have tuned the hyperparameter alpha as well to get better accuracy. Also I have tuned alpha for initial case also."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION K:\n",
    "\n",
    "- For testing (or) inference, implement the following procedure: for any sample, first predict the class label as j and then based on the class label j, use model Mj to predict the Consumption value. Using this procedure, find the RMSE values for T3 and T4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nT3,T4 = train_test_split(frame2, test_size=0.2,stratify=frame2[\\'Class\\'],random_state=seed)  # The seed value replicates the samples in T1 in T3\\n#T3.drop(columns=[\\'Consumption\\'],inplace=True)\\n#T4.drop(columns=[\\'Consumption\\'],inplace=True)\\nprint(T3.shape,T4.shape)\\nprint(\"Number of datapoints in unique classes :\", np.unique(T3[\\'Class\\'],return_counts=True))\\n'"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "T3,T4 = train_test_split(frame2, test_size=0.2,stratify=frame2['Class'],random_state=seed)  # The seed value replicates the samples in T1 in T3\n",
    "#T3.drop(columns=['Consumption'],inplace=True)\n",
    "#T4.drop(columns=['Consumption'],inplace=True)\n",
    "print(T3.shape,T4.shape)\n",
    "print(\"Number of datapoints in unique classes :\", np.unique(T3['Class'],return_counts=True))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R2 score of 1 th class in Train set : 0.9774560390885241\n",
      "R2 score of 1 th class in Test set : 0.9476283320570961\n",
      "RMSE score of 1 th class in Train set : 0.11648141760952051\n",
      "RMSE score of 1 th class in Test set : 0.16950677801845276\n",
      "\n",
      "R2 score of 2 th class in Train set : 0.7706746730427432\n",
      "R2 score of 2 th class in Test set : 0.7323234567552668\n",
      "RMSE score of 2 th class in Train set : 0.3747413400122353\n",
      "RMSE score of 2 th class in Test set : 0.40938317428544435\n",
      "\n",
      "R2 score of 3 th class in Train set : 0.6600692675833802\n",
      "R2 score of 3 th class in Test set : 0.3210089729713316\n",
      "RMSE score of 3 th class in Train set : 0.4357073548314661\n",
      "RMSE score of 3 th class in Test set : 0.5373502626075388\n",
      "\n",
      "R2 score of 4 th class in Train set : 0.680912365292819\n",
      "R2 score of 4 th class in Test set : -1.4210645599286735\n",
      "RMSE score of 4 th class in Train set : 0.4016102473534042\n",
      "RMSE score of 4 th class in Test set : 0.8424410802920868\n",
      "\n",
      "R2 score of 5 th class in Train set : 0.3937769793451853\n",
      "R2 score of 5 th class in Test set : -3.548585440533498\n",
      "RMSE score of 5 th class in Train set : 0.49172683748056023\n",
      "RMSE score of 5 th class in Test set : 1.0209804878623017\n",
      "\n",
      "R2 score of 6 th class in Train set : 0.14073456412956242\n",
      "R2 score of 6 th class in Test set : -4.248200868795875\n",
      "RMSE score of 6 th class in Train set : 0.5623184050419975\n",
      "RMSE score of 6 th class in Test set : 1.0494573144246653\n",
      "\n",
      "R2 score of 7 th class in Train set : 0.9603738578208446\n",
      "R2 score of 7 th class in Test set : 0.5879576271057683\n",
      "RMSE score of 7 th class in Train set : 0.17275336629598495\n",
      "RMSE score of 7 th class in Test set : 0.4978967275591821\n",
      "\n",
      "RMSE for T3: 1.0454528584829583\n",
      "RMSE for T4: 1.8937904774233683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "# First predict the class label for each sample in T3 and T4\n",
    "y_pred_T3_class = best_classification_model.predict(T3.drop(['Class','Consumption'], axis=1))#'Class', \n",
    "y_pred_T4_class = best_classification_model.predict(T4.drop(['Class','Consumption'], axis=1))#'Class', \n",
    "\n",
    "# Drop the Class labels from T3 and add new predicted values\n",
    "T3.drop(['Class'], axis=1,inplace=True)\n",
    "T4.drop(['Class'], axis=1,inplace=True)\n",
    "\n",
    "# Add the predicted class labels to it\n",
    "T3['pred_class']=y_pred_T3_class\n",
    "T4['pred_class']=y_pred_T4_class\n",
    "\n",
    "rmse_T3=0\n",
    "rmse_T4=0\n",
    "\n",
    "for i in choices:\n",
    "    # Filter samples belonging to class i\n",
    "    T3_i = T3[T3['pred_class'] == i].drop(['pred_class', 'Consumption'],axis=1).to_numpy()\n",
    "    T4_i = T4[T4['pred_class'] == i].drop(['pred_class', 'Consumption'],axis=1).to_numpy()\n",
    "    \n",
    "    # Predict Consumption using the corresponding kernel ridge regression model\n",
    "    y_pred_T3_i = all_models[i].predict(T3_i)\n",
    "    y_pred_T4_i = all_models[i].predict(T4_i)\n",
    "\n",
    "    # Actual Values\n",
    "    y3=T3[T3['pred_class'] == i]['Consumption'].to_numpy()\n",
    "    y4=T4[T4['pred_class'] == i]['Consumption'].to_numpy()\n",
    "    \n",
    "    # Compute the RMSE values for T3 and T4\n",
    "    rmse_T3 = np.sqrt(rmse_T3**2+mean_squared_error(y_pred_T3_i,y3))\n",
    "    rmse_T4 = np.sqrt(rmse_T4**2+mean_squared_error(y_pred_T4_i,y4))\n",
    "\n",
    "    print(f\"\\nR2 score of {i} th class in Train set :\",r2_score(y_pred_T3_i,y3))\n",
    "    print(f\"R2 score of {i} th class in Test set :\",r2_score(y_pred_T4_i,y4))\n",
    "    print(f\"RMSE score of {i} th class in Train set :\",np.sqrt(mean_squared_error(y3,y_pred_T3_i)))\n",
    "    print(f\"RMSE score of {i} th class in Test set :\",np.sqrt(mean_squared_error(y4,y_pred_T4_i)))\n",
    "\n",
    "print(\"\\nRMSE for T3:\", rmse_T3)\n",
    "print(\"RMSE for T4:\", rmse_T4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMENTS :\n",
    "\n",
    "- From the above results we can see that some classes have a higher r2 score and lower RMSE than some other classes. This can be attributed to the fact that first we have to classify the dataset into correct class and then predict the correct consumption value. So we have to factor in the classification results and the wrong model being applied."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION L:\n",
    "\n",
    "- Compare and contrast the RMSE values obtained in part (f) and part (k). Using your observations, suggest when the two-stage approach of classification-followed-by-regression would be useful when compared to the simple regression approach on the full data set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMENTS :\n",
    "\n",
    "- From the RMSE results of (f) and (k) we get that the RMSE of the k part is greater than f. \n",
    "\n",
    "- This can be due to the fact that proper and equal resampling did not take place in this case as there was a huge disparity in initial the number of classes given. So it was not possible to exactly resample each class to the desired values.\n",
    "\n",
    "- These resampling techniques may not be always correct as the data is synthetically generated and may include noise.\n",
    "\n",
    "- However, we are getting very good results in some classes whereas very bad data in others.\n",
    "\n",
    "- Another fact to keep in mind is that the standardization is different for different classes whereas in simple regression it is a uniform standardization. So, if a class is wrongly classified is judged with another model then the error becomes significant.\n",
    "\n",
    "- The two step approach can be used when we have balanced classes and the accuracy is above 95%. Here that is not the case.\n",
    "\n",
    "- Also we should ensure there is very less noise in the dataset. Standardization should be uniform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
